{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_DL_CODE2024/blob/main/dl05_cnn.ipynb\" target=\"_parent\">\n",
    "      <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcinsawinski/UEP_KIE_DL_CODE2024/blob/main/dl05_cnn.ipynb\">\n",
    "      <img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://studiolab.sagemaker.aws/import/github/marcinsawinski/UEP_KIE_DL_CODE2024/blob/main/dl05_cnn.ipynb\">\n",
    "      <img src=\"https://studiolab.sagemaker.aws/studiolab.svg\" alt=\"Open in SageMaker Studio Lab\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation - Setup [WandB](https://wandb.ai) and [PyTorch Lightning](https://lightning.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install  wandb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "Check tutorial:\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "\n",
    "1. Install and connect to [WandB](https://wandb.ai)\n",
    "2. Build CNN model for classification on Fashion MNIST dataset. Log training to WandB in own project.\n",
    "3. Create hyperparameter search with WandB sweep.\n",
    "4. Try to learn best CNN for CIFAR-10\n",
    "5. Use pretrained CNNs (like ResNet, VGG, MobileNet). They are trained on large datasets like ImageNet (millions of images).\n",
    " - They already know how to detect basic things: edges, textures, shapes, etc.\n",
    " - You can fine-tune them (adjust weights a bit) or just reuse them as feature extractors.\n",
    " - https://pytorch.org/hub/pytorch_vision_resnet/\n",
    " - https://pytorch.org/hub/pytorch_vision_vgg/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "from typing import Any, Dict\n",
    "\n",
    "class CnnClassifier(pl.LightningModule):\n",
    "    def __init__(self, cfg: Dict[str, Any]):\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters(cfg)\n",
    "        self.cfg = cfg\n",
    "        self.model = self.build_model()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Metrics\n",
    "        self.train_metrics = self.create_metrics(prefix=\"train/\")\n",
    "        self.valid_metrics = self.create_metrics(prefix=\"valid/\")\n",
    "        self.test_metrics = self.create_metrics(prefix=\"test/\")\n",
    "\n",
    "    def build_model(self):\n",
    "        dropout = self.cfg.get('dropout', 0.0)\n",
    "        num_classes = self.cfg['num_classes']\n",
    "        activation_cls = getattr(nn, self.cfg.get('activation', 'ReLU'))\n",
    "        \n",
    "        layers = [\n",
    "        ]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def create_metrics(self, prefix: str) -> torchmetrics.MetricCollection:\n",
    "        num_classes = self.cfg['num_classes']\n",
    "        return torchmetrics.MetricCollection({\n",
    "            \"accuracy\": torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
    "            \"f1\": torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=num_classes),\n",
    "        }, prefix=prefix)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def step(self, batch: Any, metrics: torchmetrics.MetricCollection, step_type: str) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        metrics.update(logits, y)\n",
    "        self.log(f\"{step_type}/loss\", loss, on_step=(step_type == \"train\"), \n",
    "         on_epoch=(step_type != \"train\"), prog_bar=True,)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int) -> torch.Tensor:\n",
    "        loss = self.step(batch, self.train_metrics, \"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        self.step(batch, self.valid_metrics, \"valid\")\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        self.step(batch, self.test_metrics, \"test\")\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.log_dict(self.train_metrics.compute(), prog_bar=True)\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.log_dict(self.valid_metrics.compute(), prog_bar=True)\n",
    "        self.valid_metrics.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        self.log_dict(self.test_metrics.compute(), prog_bar=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.cfg['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Example normalization\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download datasets\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Split train_dataset into train and valid\n",
    "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "valid_size = len(train_dataset) - train_size  # 20% for validation\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "    train_dataset,\n",
    "    [train_size, valid_size],\n",
    "    generator=torch.Generator().manual_seed(42),  # For reproducibility\n",
    ")\n",
    "\n",
    "# Now you have:\n",
    "# - train_dataset (80% of original train)\n",
    "# - valid_dataset (20% of original train)\n",
    "# - test_dataset (the original test set)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "def train(config=None, project = None):\n",
    "    with wandb.init(config=config,project = project):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        cfg = wandb.config\n",
    "        name = f\"{cfg['architecture']}_lr{cfg['learning_rate']:.1e}_ep{cfg['epochs']}_bs{cfg['batch_size']}_bn{cfg['batch_norm']}_act{cfg['activation']}_do{cfg['dropout']}_hs{'-'.join([str(x) for x in cfg['hidden_sizes']])}_{time.strftime('%m%d-%H%M')}\"\n",
    "        wandb.run.name = name\n",
    "        # Create model\n",
    "        model = CnnClassifier(cfg)\n",
    "        wandb_logger = WandbLogger()\n",
    "        wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "\n",
    "        # Create trainer\n",
    "        trainer = Trainer(\n",
    "            logger=wandb_logger,\n",
    "            max_epochs=cfg['epochs'],\n",
    "            accelerator=\"auto\",\n",
    "            devices=1,\n",
    "            callbacks=[EarlyStopping(monitor=\"valid/accuracy\", mode=\"max\", min_delta=0.00, patience=3)]\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        trainer.fit(model, train_loader, valid_loader)\n",
    "\n",
    "        # (optional) Test\n",
    "        trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"owner\": \"kowalski_jan\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"activation\":'ReLU',\n",
    "    \"batch_norm\":True,\n",
    "    \"dropout\":0.3,\n",
    "    \"dataset\": \"FMNIST\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_classes\":10,\n",
    "    \"input_size\":28*28,\n",
    "    \"hidden_sizes\": [512, 256, 128],\n",
    "    \n",
    "}\n",
    "user = \"kowalski_jan\" # your name here \n",
    "project = f\"student_{user}_FMNIST_LIGHTNING\"\n",
    "train(config=cfg, project=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "\n",
    "sweep_config = {\"method\": \"random\"}\n",
    "metric = {\"name\": \"valid/f1\", \"goal\": \"minimize\"}\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    \"owner\": {\"value\": \"kowalski_jan\"},\n",
    "    \"epochs\": {\"value\": 25},\n",
    "    \"architecture\": {\"value\": \"CNN\"},\n",
    "    \"input_size\":{\"value\": 28*28},\n",
    "    \"hidden_sizes\": {\"value\": [512, 256, 128]},\n",
    "    \"dataset\": {\"value\": 'FMNIST'},\n",
    "    \"num_classes\": {\"value\": 10},\n",
    "    \"dropout\": {\"values\": [0.0, 0.3, 0.5]},\n",
    "    \"batch_norm\":{\"values\":[True, False]},\n",
    "    \"activation\":{\"values\":['Sigmoid', 'ReLU']},\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update({})\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-3,\n",
    "            \"max\": 1e-2,\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            # integers between 32 and 256\n",
    "            # with evenly-distributed logarithms\n",
    "            \"distribution\": \"q_log_uniform_values\",\n",
    "            \"q\": 8,\n",
    "            \"min\": 16,\n",
    "            \"max\": 64,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "pp(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = f\"student_{sweep_config['parameters']['owner']['value']}_FMNIST_LIGHTNING\"\n",
    "sweep_id = wandb.sweep(sweep_config, project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
